import { fal } from "@fal-ai/client";
import { ENV } from "@ffh/env";
import { convex } from "@ffh/db";
import { api } from "../../../../convex/_generated/api";
import { getSystemPrompt } from "../prompts";
import { optimizeForTTS } from "../prompts/pronunciation-guide";
import { getProblemIntro } from "../services/problem-intros";
import type {
  ClientMessage,
  ServerMessage,
  VoicePipelineState,
  MessageRole,
  InterviewType,
  Difficulty,
  CodeLanguage,
  TestResult,
  WhiteboardState,
} from "@ffh/types";

// â”€â”€â”€ fal.ai config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

fal.config({ credentials: ENV.FAL_KEY });

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface ChatMessage {
  role: MessageRole;
  content: string;
}

interface SessionConfig {
  language: string;
  speed: number;
}

interface InterviewInfo {
  id: string;
  type: InterviewType;
  difficulty: Difficulty;
  language: string;
  userId: string;
  jobPostingId?: string;
  resumeId?: string;
  memoryEnabled?: boolean;
}

// â”€â”€â”€ Voice Session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export class VoiceSession {
  private state: VoicePipelineState = "idle";
  private audioChunks: string[] = [];
  private conversationHistory: ChatMessage[] = [];
  private userLocation: string = "Unknown";
  private userCountry: string = "Unknown";
  private userIP: string = "Unknown";
  private isFirstInteraction: boolean = true;
  private config: SessionConfig = { language: "tr", speed: 1.0 };
  private abortController: AbortController | null = null;
  private send: (msg: ServerMessage) => void;
  private interview: InterviewInfo | null = null;
  private initialized = false;
  private currentCode: string = "";
  private currentCodeLanguage: CodeLanguage = "javascript";
  private hintCount: number = 0;
  private processing = false; // Guards against concurrent pipeline runs
  private consecutiveErrors = 0; // Track consecutive pipeline errors for connection fallback
  private currentWhiteboardState: WhiteboardState | null = null;



  // Question tracking (phone-screen)
  private currentQuestion: number = 0;
  private totalQuestions: number = 5;
  private recommendedSecondsPerQuestion: number = 300; // default 5 min

  // Time limit tracking
  private timeLimitMs: number = 0; // 0 = no limit
  private startTime: number = 0;
  private timeWarningTimer: ReturnType<typeof setTimeout> | null = null;
  private timeUpTimer: ReturnType<typeof setTimeout> | null = null;

  // Design problem reference for system-design intro
  private currentDesignProblem: {
    title?: string;
    description?: string;
    difficulty?: string;
    requirements?: {
      functional: string[];
      nonFunctional: string[];
    };
    discussionPoints?: string[];
  } | null = null;

  // Problem reference for solution comparison and intro generation
  private currentProblem: {
    title?: string;
    slug?: string;
    description?: string;
    difficulty?: string;
    relatedTopics?: string[];
    optimalSolution?: string;
    timeComplexity?: string;
    spaceComplexity?: string;
  } | null = null;

  constructor(send: (msg: ServerMessage) => void) {
    this.send = send;
  }

  /**
   * Initialize with interview data â€” loads config, prompt, and history from Convex.
   */
  async init(interviewId: string, problemId?: string): Promise<void> {
    if (this.initialized) return;

    try {
      const interview = await convex.query(api.interviews.getById, {
        id: interviewId as any,
      });

      this.interview = {
        id: interview._id,
        type: interview.type as InterviewType,
        difficulty: interview.difficulty as Difficulty,
        language: interview.language,
        userId: interview.userId,
        jobPostingId: interview.jobPostingId ?? undefined,
        resumeId: interview.resumeId ?? undefined,
        memoryEnabled: interview.memoryEnabled ?? undefined,
      };

      this.config.language = interview.language;
      this.totalQuestions = interview.questionCount ?? 5;

      // Time limits per type
      if (this.interview.type === "phone-screen") {
        const timeLimitsMin: Record<string, number> = { easy: 15, medium: 25, hard: 35 };
        this.timeLimitMs = (timeLimitsMin[this.interview.difficulty] ?? 25) * 60 * 1000;
      } else if (this.interview.type === "live-coding") {
        const timeLimitsMin: Record<string, number> = { easy: 20, medium: 30, hard: 45 };
        this.timeLimitMs = (timeLimitsMin[this.interview.difficulty] ?? 30) * 60 * 1000;
      } else if (this.interview.type === "system-design") {
        const timeLimitsMin: Record<string, number> = { easy: 25, medium: 35, hard: 45 };
        this.timeLimitMs = (timeLimitsMin[this.interview.difficulty] ?? 35) * 60 * 1000;
      }

      // Build system prompt based on interview config
      const systemPrompt = getSystemPrompt(
        this.interview.type,
        this.interview.difficulty,
        this.interview.language,
      );
      this.conversationHistory.push({ role: "system", content: systemPrompt });

      // â”€â”€ Personalization Context (Faz 6) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      await this.loadPersonalizationContext();

      // For system-design interviews, load a design problem
      if (this.interview.type === "system-design") {
        try {
          let designProblem = await convex.query(api.designProblems.getRandom, {
            difficulty: this.interview.difficulty as any,
            seed: Math.random(),
          });

          // If no design problems exist, seed the table and retry
          if (!designProblem) {
            console.log("[init] No design problems found, seeding...");
            try {
              await convex.mutation(api.designProblems.seedIfEmpty, {});
              designProblem = await convex.query(api.designProblems.getRandom, {
                difficulty: this.interview.difficulty as any,
                seed: Math.random(),
              });
            } catch (seedErr) {
              console.error("Failed to seed design problems:", seedErr);
            }
          }

          if (designProblem) {
            console.log(`[init] Sending design_problem_loaded: ${designProblem.title}`);
            this.send({ type: "design_problem_loaded", problem: designProblem as any });
            // Store design problem info for intro generation
            this.currentDesignProblem = designProblem as any;
            // Add design problem context to conversation
            const reqText = [
              "Fonksiyonel Gereksinimler:",
              ...designProblem.requirements.functional.map((r: string) => `  - ${r}`),
              "Non-Fonksiyonel Gereksinimler:",
              ...designProblem.requirements.nonFunctional.map((r: string) => `  - ${r}`),
            ].join("\n");

            this.conversationHistory.push({
              role: "system",
              content: `[Atanan problem â€” aday bunu sol panelde gÃ¶rÃ¼yor, madde madde tekrarlama]\nBaÅŸlÄ±k: ${designProblem.title}\nAÃ§Ä±klama: ${designProblem.description}\n\n${reqText}\n\nAdaya kÄ±sa bir giriÅŸ yap ve whiteboard'a Ã§izmeye baÅŸlamasÄ±nÄ± iste.`,
            });
            // Link design problem to interview
            try {
              await convex.mutation(api.interviews.setDesignProblem, {
                id: interviewId as any,
                designProblemId: designProblem._id,
              });
            } catch {
              // Non-fatal
            }
          } else {
            console.error("[init] No design problems available even after seeding");
          }
        } catch (err) {
          console.error("Failed to load design problem:", err);
        }
      }

      // For live-coding and practice interviews, load a specific or random problem
      if (this.interview.type === "live-coding" || this.interview.type === "practice") {
        console.log(`Loading problem for ${this.interview.type}, difficulty: ${this.interview.difficulty}, problemId: ${problemId || 'random'}`);
        try {
          let problem: any;
          if (problemId) {
            // Try leetcodeProblems first, then fall back to legacy problems
            try {
              const lc = await convex.query(api.leetcodeProblems.getById, {
                id: problemId as any,
              });
              if (lc) {
                problem = {
                  ...lc,
                  category: lc.relatedTopics?.[0] ?? "general",
                  testCases: [],
                };
              }
            } catch {
              // Not a leetcode problem ID, try legacy
              problem = await convex.query(api.problems.getById, {
                id: problemId as any,
              });
            }
            console.log("Specific problem loaded:", problem?._id);
          } else {
            // Load random problem from leetcodeProblems table (real question bank)
            const lc = await convex.query(api.leetcodeProblems.getRandom, {
              difficulty: this.interview.difficulty as any,
              seed: Math.random(), // Pass seed to avoid Convex query determinism
            });
            if (lc) {
              problem = {
                ...lc,
                category: lc.relatedTopics?.[0] ?? "general",
                testCases: [],
              };
            } else {
              // Fallback to legacy problems table if leetcode table is empty
              problem = await convex.query(api.problems.getRandom, {
                difficulty: this.interview.difficulty as any,
              });
            }
            console.log("Random problem loaded:", problem?._id, problem?.title);
          }
          if (problem) {
            this.send({ type: "problem_loaded", problem: problem as any });
            // Store problem info for solution comparison and intro generation
            this.currentProblem = {
              title: problem.title,
              slug: problem.slug || problem.title.toLowerCase().replace(/\s+/g, '-'),
              description: problem.description,
              difficulty: problem.difficulty,
              relatedTopics: problem.relatedTopics ?? [],
              optimalSolution: problem.optimalSolution ?? undefined,
              timeComplexity: problem.timeComplexity ?? undefined,
              spaceComplexity: problem.spaceComplexity ?? undefined,
            };
            // Build rich problem context for AI
            const contextParts: string[] = [
              `[MÃ¼lakata atanan problem]`,
              `BaÅŸlÄ±k: ${problem.title}`,
              `Zorluk: ${problem.difficulty}`,
            ];

            // Category / topics
            if (problem.relatedTopics?.length > 0) {
              contextParts.push(`Ä°lgili Konular: ${problem.relatedTopics.join(", ")}`);
            } else if (problem.category) {
              contextParts.push(`Kategori: ${problem.category}`);
            }

            // Companies context (shows this is a real interview question)
            if (problem.companies?.length > 0) {
              contextParts.push(`Bu soru ÅŸu ÅŸirketlerde sorulmuÅŸtur: ${problem.companies.slice(0, 5).join(", ")}`);
            }

            // Full description
            contextParts.push(`\nProblem AÃ§Ä±klamasÄ±:\n${problem.description}`);

            // Test cases (from problems table)
            if (problem.testCases?.length > 0) {
              const visibleTests = problem.testCases.filter((tc: any) => !tc.isHidden);
              if (visibleTests.length > 0) {
                contextParts.push(`\nÃ–rnek Test Case'ler:`);
                for (const tc of visibleTests.slice(0, 3)) {
                  contextParts.push(`  Girdi: ${tc.input} â†’ Beklenen Ã‡Ä±ktÄ±: ${tc.expectedOutput}`);
                }
              }
            }

            // Complexity hints
            if (problem.timeComplexity) {
              contextParts.push(`Beklenen Zaman KarmaÅŸÄ±klÄ±ÄŸÄ±: ${problem.timeComplexity}`);
            }
            if (problem.spaceComplexity) {
              contextParts.push(`Beklenen Alan KarmaÅŸÄ±klÄ±ÄŸÄ±: ${problem.spaceComplexity}`);
            }

            // Interview behavior instructions
            contextParts.push(`\n--- MÃœLAKAT TALÄ°MATLARI ---`);
            contextParts.push(`Bu bir teknik mÃ¼lakat sorusudur. Sen mÃ¼lakatÃ§Ä±sÄ±n, aday bu problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸacak.`);
            contextParts.push(`1. Problemi doÄŸal bir dille aÃ§Ä±kla (kod syntax'Ä± kullanma).`);
            contextParts.push(`2. AdayÄ±n yaklaÅŸÄ±mÄ±nÄ± sor, direkt Ã§Ã¶zÃ¼m verme.`);
            contextParts.push(`3. Aday kodlarken sessiz kal, sadece takÄ±lÄ±rsa veya hata yaparsa yÃ¶nlendir.`);
            contextParts.push(`4. Test sonuÃ§larÄ±nÄ± deÄŸerlendir, edge case'leri hatÄ±rlat.`);
            contextParts.push(`5. Her zaman bu probleme odaklan â€” konu dÄ±ÅŸÄ±na Ã§Ä±kma.`);

            this.conversationHistory.push({
              role: "system",
              content: contextParts.join("\n"),
            });
            // Link problem to interview (only for legacy problems table)
            if (!problem.leetcodeId) {
              try {
                await convex.mutation(api.interviews.setProblem, {
                  id: interviewId as any,
                  problemId: problem._id,
                });
              } catch {
                // Non-fatal
              }
            }
          }
        } catch (err) {
          console.error("Failed to load problem:", err);
        }
      }

      // Load existing messages from Convex (reconnect support)
      const existingMessages = await convex.query(api.messages.getRecent, {
        interviewId: interviewId as any,
        limit: 50,
      });

      for (const msg of existingMessages) {
        if (msg.role === "user" || msg.role === "assistant") {
          this.conversationHistory.push({
            role: msg.role,
            content: msg.content,
          });
        }
      }

      this.initialized = true;

      // Send initial question counter for phone-screen
      if (this.interview.type === "phone-screen") {
        this.currentQuestion = 1;
        // Recommended seconds per question based on total time / question count
        const totalMinutes: Record<string, number> = { easy: 15, medium: 25, hard: 35 };
        const totalMin = totalMinutes[this.interview.difficulty] ?? 25;
        this.recommendedSecondsPerQuestion = Math.floor((totalMin * 60) / this.totalQuestions);
        this.send({
          type: "question_update",
          current: this.currentQuestion,
          total: this.totalQuestions,
          questionStartTime: Date.now(),
          recommendedSeconds: this.recommendedSecondsPerQuestion,
        });
      }

      // Start time limit timers
      if (this.timeLimitMs > 0) {
        this.startTime = Date.now();
        // Warning at 80% of time
        const warningMs = this.timeLimitMs * 0.8;
        this.timeWarningTimer = setTimeout(() => {
          const minutesLeft = Math.ceil((this.timeLimitMs - (Date.now() - this.startTime)) / 60000);
          this.send({ type: "time_warning", minutesLeft });
          // Inject time warning into conversation so AI knows
          this.conversationHistory.push({
            role: "system",
            content: `[SYSTEM: MÃ¼lakatÄ±n bitmesine yaklaÅŸÄ±k ${minutesLeft} dakika kaldÄ±. EÄŸer henÃ¼z sormadÄ±ysan son bir soru sor ve mÃ¼lakatÄ± nazikÃ§e sonlandÄ±rmaya baÅŸla.]`,
          });
        }, warningMs);
        // Time up
        this.timeUpTimer = setTimeout(() => {
          this.conversationHistory.push({
            role: "system",
            content: `[SYSTEM: MÃ¼lakat sÃ¼resi doldu. Adaya teÅŸekkÃ¼r et ve mÃ¼lakatÄ± sonlandÄ±r. KÄ±sa ve nazik ol.]`,
          });
          // Trigger AI to wrap up
          this.triggerAIResponse();
        }, this.timeLimitMs);
      }
    } catch (err) {
      const message = err instanceof Error ? err.message : "Interview yÃ¼klenemedi";
      this.send({ type: "error", message });
    }
  }

  /**
   * Initialize without an interview â€” free mode with default prompt.
   */
  initFreeMode(): void {
    if (this.initialized) return;

    this.conversationHistory.push({
      role: "system",
      content: `Sen Wingman adÄ±nda deneyimli bir teknik mÃ¼lakatÃ§Ä±sÄ±n. TÃ¼rkÃ§e konuÅŸuyorsun. 
AdayÄ± profesyonel ama samimi bir ÅŸekilde karÅŸÄ±la. SorularÄ±nÄ± net ve anlaÅŸÄ±lÄ±r sor.
CevaplarÄ± deÄŸerlendirirken yapÄ±cÄ± ol. KÄ±sa ve Ã¶z konuÅŸ â€” her cevabÄ±n 2-3 cÃ¼mleyi geÃ§mesin.`,
    });
    this.initialized = true;
  }

  async handleMessage(raw: string): Promise<void> {
    let msg: ClientMessage;
    try {
      msg = JSON.parse(raw);
    } catch {
      this.send({ type: "error", message: "GeÃ§ersiz mesaj formatÄ±" });
      return;
    }

    switch (msg.type) {
      case "config":
        if (msg.language) this.config.language = msg.language;
        if (msg.speed) this.config.speed = msg.speed;
        break;

      case "start_listening":
        this.audioChunks = [];
        this.setState("listening");

        // Ä°lk mikrofon aÃ§Ä±ldÄ±ÄŸÄ±nda intro sesini Ã§al
        console.log(`[start_listening] isFirstInteraction: ${this.isFirstInteraction}, type: ${this.interview?.type}`);
        if (this.isFirstInteraction && this.interview) {
          this.isFirstInteraction = false;

          if (this.interview.type === "live-coding") {
            // Live-coding: problem is visible in the panel, just greet briefly
            console.log("[start_listening] Live-coding â€” short greeting...");

            const introText = "Selam! Soruyu sol tarafta gÃ¶rÃ¼yorsun, takÄ±ldÄ±ÄŸÄ±n yer olursa yardÄ±mcÄ± olurum.";

            this.send({ type: "ai_text", text: introText, done: true });

            // Persist intro to conversation history
            this.conversationHistory.push({ role: "assistant", content: introText });
            this.persistMessage("assistant", introText);

            // Generate TTS audio
            this.generateIntroAudio(introText);

          } else if (this.interview.type === "practice") {
            console.log("[start_listening] Practice â€” playing problem intro audio...");

            // Check if problem is loaded
            if (this.currentProblem?.slug) {
              const problemSlug = this.currentProblem.slug;
              console.log("[start_listening] Using problem slug:", problemSlug);

              const introText = getProblemIntro(problemSlug, this.currentProblem);
              console.log("[start_listening] Intro text:", introText.substring(0, 100) + "...");

              // Send the intro text to the client immediately
              this.send({ type: "ai_text", text: introText, done: true });

              // Persist intro to conversation history
              this.conversationHistory.push({ role: "assistant", content: introText });
              this.persistMessage("assistant", introText);

              // Generate TTS audio
              this.generateIntroAudio(introText);
            } else {
              // If problem not loaded yet, wait a bit and retry
              console.log("[start_listening] Problem not loaded yet, waiting...");
              setTimeout(() => {
                if (this.currentProblem?.slug) {
                  const problemSlug = this.currentProblem.slug;
                  const introText = getProblemIntro(problemSlug, this.currentProblem);
                  this.send({ type: "ai_text", text: introText, done: true });
                  this.conversationHistory.push({ role: "assistant", content: introText });
                  this.persistMessage("assistant", introText);
                  this.generateIntroAudio(introText);
                } else {
                  // Fallback to LLM
                  this.conversationHistory.push({
                    role: "user",
                    content: "[SYSTEM: KullanÄ±cÄ± hazÄ±r, problemi aÃ§Ä±klamaya baÅŸla]",
                  });
                  this.triggerAIResponse();
                }
              }, 500); // Wait 500ms for problem to load
            }
          } else if (this.interview.type === "system-design") {
            // System design: short greeting, problem is visible in the panel
            console.log("[start_listening] System design â€” playing short greeting...");

            if (this.currentDesignProblem?.title) {
              const introText = `Selam! Bu mÃ¼lakatÄ±nda sana ben yardÄ±mcÄ± olacaÄŸÄ±m. Problemi sol panelde gÃ¶rebilirsin. HazÄ±r olduÄŸunda baÅŸlayalÄ±m.`;

              this.send({ type: "ai_text", text: introText, done: true });

              // Persist AI intro
              this.conversationHistory.push({ role: "assistant", content: introText });
              this.persistMessage("assistant", introText);

              // Generate TTS audio for the intro
              this.generateIntroAudio(introText);
            } else {
              // No design problem loaded, use LLM to generate the question
              console.log("[start_listening] No design problem loaded, using LLM...");
              this.conversationHistory.push({
                role: "user",
                content: "[SYSTEM: KullanÄ±cÄ± hazÄ±r, system design problemi sor ve aÃ§Ä±kla]",
              });
              this.triggerAIResponse();
            }
          } else if (this.interview.type === "phone-screen") {
            // Phone screen: AI introduces itself and starts with the first question
            console.log("[start_listening] Phone screen â€” triggering AI intro...");
            this.conversationHistory.push({
              role: "user",
              content: "[SYSTEM: KullanÄ±cÄ± hazÄ±r, mÃ¼lakata baÅŸla ve ilk soruyu sor]",
            });
            this.triggerAIResponse();
          }
        }
        break;

      case "audio_chunk":
        if (this.state === "listening") {
          this.audioChunks.push(msg.data);
        }
        break;

      case "stop_listening":
        if (this.state === "listening" && this.audioChunks.length > 0 && !this.processing) {
          await this.processAudio();
        } else if (!this.processing) {
          this.setState("idle");
        }
        break;

      case "interrupt":
        this.handleInterrupt();
        break;

      case "code_update":
        this.currentCode = msg.code;
        this.currentCodeLanguage = msg.language;
        break;

      case "code_result":
        await this.handleCodeResult(msg.results, msg.stdout, msg.stderr, msg.error);
        break;

      case "hint_request":
        if (!this.processing) {
          await this.handleHintRequest();
        }
        break;

      case "whiteboard_update":
        this.handleWhiteboardUpdate(msg.state);
        break;
    }
  }

  // â”€â”€â”€ Personalization Context (Faz 6) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async loadPersonalizationContext(): Promise<void> {
    if (!this.interview) return;

    const parts: string[] = [];

    // 1. Job Posting context
    if (this.interview.jobPostingId) {
      try {
        const job = await convex.query(api.jobPostings.getById, {
          id: this.interview.jobPostingId as any,
        });
        if (job) {
          parts.push(
            `[Hedef Pozisyon Bilgisi]\nBaÅŸlÄ±k: ${job.title}${job.company ? `\nÅžirket: ${job.company}` : ""}${job.level ? `\nSeviye: ${job.level}` : ""}\nGereksinimler:\n${job.requirements.map((r) => `  - ${r}`).join("\n")}\nAranan Yetenekler: ${job.skills.join(", ")}\n\nBu pozisyona uygun sorular sor. Ä°landaki gereksinimlere ve yeteneklere odaklan. AdayÄ±n bu pozisyona uygunluÄŸunu deÄŸerlendir.`,
          );
        }
      } catch {
        // non-fatal
      }
    }

    // 2. Resume context (Deep Analysis)
    if (this.interview.resumeId) {
      try {
        const resume = await convex.query(api.resumes.getById, {
          id: this.interview.resumeId as any,
        });
        if (resume) {
          const resumeParts: string[] = ["[Aday Ã–zgeÃ§miÅŸ Bilgisi â€” DetaylÄ± Analiz]"];

          // Basic info
          if (resume.name) resumeParts.push(`Ä°sim: ${resume.name}`);
          if (resume.title) resumeParts.push(`Mevcut Pozisyon: ${resume.title}`);
          if (resume.yearsOfExperience) resumeParts.push(`Toplam Deneyim: ${resume.yearsOfExperience} yÄ±l`);

          // Professional summary
          if (resume.summary) {
            resumeParts.push(`\nðŸ“‹ Profesyonel Ã–zet:\n${resume.summary}`);
          }

          // Categorized skills
          const cs = resume.categorizedSkills as any;
          if (cs) {
            resumeParts.push("\nðŸ› ï¸ Teknik Yetenekler (Kategorize):");
            if (cs.programmingLanguages?.length > 0) resumeParts.push(`  Programlama Dilleri: ${cs.programmingLanguages.join(", ")}`);
            if (cs.frameworks?.length > 0) resumeParts.push(`  Framework'ler: ${cs.frameworks.join(", ")}`);
            if (cs.databases?.length > 0) resumeParts.push(`  VeritabanlarÄ±: ${cs.databases.join(", ")}`);
            if (cs.tools?.length > 0) resumeParts.push(`  AraÃ§lar: ${cs.tools.join(", ")}`);
            if (cs.cloud?.length > 0) resumeParts.push(`  Cloud/DevOps: ${cs.cloud.join(", ")}`);
            if (cs.methodologies?.length > 0) resumeParts.push(`  Metodolojiler: ${cs.methodologies.join(", ")}`);
            if (cs.other?.length > 0) resumeParts.push(`  DiÄŸer: ${cs.other.join(", ")}`);
          } else if (resume.skills.length > 0) {
            resumeParts.push(`\nðŸ› ï¸ Yetenekler: ${resume.skills.join(", ")}`);
          }

          // Full experience (no limit)
          if (resume.experience.length > 0) {
            resumeParts.push("\nðŸ’¼ Ä°ÅŸ Deneyimi:");
            for (const exp of resume.experience) {
              const techStr = (exp as any).technologies?.length > 0
                ? ` [Teknolojiler: ${(exp as any).technologies.join(", ")}]`
                : "";
              resumeParts.push(`  â–¸ ${exp.role} @ ${exp.company} (${exp.duration})${techStr}`);
              for (const h of exp.highlights) {
                resumeParts.push(`    â€¢ ${h}`);
              }
            }
          }

          // Projects
          const projects = (resume as any).projects;
          if (projects?.length > 0) {
            resumeParts.push("\nðŸš€ Projeler:");
            for (const proj of projects) {
              resumeParts.push(`  â–¸ ${proj.name}: ${proj.description}`);
              if (proj.technologies?.length > 0) {
                resumeParts.push(`    Teknolojiler: ${proj.technologies.join(", ")}`);
              }
              for (const h of proj.highlights || []) {
                resumeParts.push(`    â€¢ ${h}`);
              }
            }
          }

          // Education
          if (resume.education.length > 0) {
            resumeParts.push("\nðŸŽ“ EÄŸitim:");
            for (const edu of resume.education) {
              const extras: string[] = [];
              if ((edu as any).year) extras.push((edu as any).year);
              if ((edu as any).gpa) extras.push(`GPA: ${(edu as any).gpa}`);
              const extraStr = extras.length > 0 ? ` (${extras.join(", ")})` : "";
              resumeParts.push(`  â–¸ ${edu.degree}, ${edu.school}${extraStr}`);
            }
          }

          // Certifications
          const certs = (resume as any).certifications;
          if (certs?.length > 0) {
            resumeParts.push("\nðŸ“œ Sertifikalar:");
            for (const cert of certs) {
              const yearStr = cert.year ? ` (${cert.year})` : "";
              resumeParts.push(`  â–¸ ${cert.name} â€” ${cert.issuer}${yearStr}`);
            }
          }

          // Languages
          const langs = (resume as any).languages;
          if (langs?.length > 0) {
            resumeParts.push(`\nðŸŒ Diller: ${langs.join(", ")}`);
          }

          // Key achievements
          const achievements = (resume as any).keyAchievements;
          if (achievements?.length > 0) {
            resumeParts.push("\nðŸ† Ã–ne Ã‡Ä±kan BaÅŸarÄ±lar:");
            for (const a of achievements) {
              resumeParts.push(`  â˜… ${a}`);
            }
          }

          // Interview topics (AI-suggested)
          const topics = (resume as any).interviewTopics;
          if (topics?.length > 0) {
            resumeParts.push("\nðŸŽ¯ Ã–nerilen MÃ¼lakat KonularÄ± (CV'ye Ã¶zel):");
            for (const t of topics) {
              resumeParts.push(`  â†’ ${t}`);
            }
          }

          // Instructions for using CV data
          resumeParts.push(`
--- Ã–ZGEÃ‡MÄ°Åž KULLANIM TALÄ°MATLARI ---
1. AdayÄ±n Ã¶zgeÃ§miÅŸindeki spesifik deneyimlere, projelere ve baÅŸarÄ±lara referans vererek sorular sor.
2. "Ã–zgeÃ§miÅŸinde X gÃ¶rdÃ¼m, bunu detaylandÄ±rÄ±r mÄ±sÄ±n?" gibi kiÅŸiselleÅŸtirilmiÅŸ sorular sor.
3. AdayÄ±n kullandÄ±ÄŸÄ± teknolojiler hakkÄ±nda derinlemesine teknik sorular sor.
4. SayÄ±sal baÅŸarÄ±larÄ± (performans artÄ±ÅŸÄ±, kullanÄ±cÄ± sayÄ±sÄ± vb.) sorgula ve detaylandÄ±rmasÄ±nÄ± iste.
5. Projelerdeki teknik kararlarÄ± ve trade-off'larÄ± sor.
6. YukarÄ±daki "Ã–nerilen MÃ¼lakat KonularÄ±"nÄ± aktif olarak kullan.
7. AdayÄ±n deneyim seviyesine uygun zorlukta sorular sor.
8. TakÄ±m Ã§alÄ±ÅŸmasÄ±, liderlik ve iletiÅŸim becerilerini de deÄŸerlendir.`);

          parts.push(resumeParts.join("\n"));
        }
      } catch {
        // non-fatal
      }
    }

    // 3. User Profile context
    try {
      const profile = await convex.query(api.userProfiles.getByUser, {
        userId: this.interview.userId as any,
      });
      if (profile && (profile.interests.length > 0 || profile.goals)) {
        let profileText = "[Aday Profil Bilgisi]";
        if (profile.interests.length > 0) {
          profileText += `\nÄ°lgi AlanlarÄ±: ${profile.interests.join(", ")}`;
        }
        if (profile.goals) {
          profileText += `\nHedefler: ${profile.goals}`;
        }
        parts.push(profileText);
      }
    } catch {
      // non-fatal
    }

    // 4. Memory context (past performance)
    if (this.interview.memoryEnabled) {
      try {
        const memoryEntries = await convex.query(api.userMemory.getAllByUser, {
          userId: this.interview.userId as any,
        });

        if (memoryEntries.length > 0) {
          const memoryLines: string[] = ["[GeÃ§miÅŸ Performans HafÄ±zasÄ±]"];

          for (const entry of memoryEntries) {
            try {
              const parsed = JSON.parse(entry.value);
              if (entry.key === "weak_topics" && Array.isArray(parsed) && parsed.length > 0) {
                memoryLines.push(`ZayÄ±f Konular: ${parsed.join(", ")}`);
              } else if (entry.key === "strong_topics" && Array.isArray(parsed) && parsed.length > 0) {
                memoryLines.push(`GÃ¼Ã§lÃ¼ Konular: ${parsed.join(", ")}`);
              } else if (entry.key === "avg_score") {
                memoryLines.push(`Ortalama Skor: ${parsed}`);
              } else if (entry.key === "total_interviews") {
                memoryLines.push(`Toplam MÃ¼lakat: ${parsed}`);
              } else if (entry.key === "improvement_notes" && typeof parsed === "string") {
                memoryLines.push(`GeliÅŸim NotlarÄ±: ${parsed}`);
              }
            } catch {
              // skip unparseable
            }
          }

          if (memoryLines.length > 1) {
            memoryLines.push(
              "\nBu bilgileri kullanarak adayÄ±n zayÄ±f yÃ¶nlerinde daha fazla soru sor. GeliÅŸim gÃ¶sterdiÄŸi konularda bunu takdir et. GeÃ§miÅŸ performansÄ±na gÃ¶re zorluk seviyesini ayarla.",
            );
            parts.push(memoryLines.join("\n"));
          }
        }
      } catch {
        // non-fatal
      }
    }

    // Inject all personalization parts as a single system message
    if (parts.length > 0) {
      this.conversationHistory.push({
        role: "system",
        content: parts.join("\n\n"),
      });
    }
  }

  // â”€â”€â”€ Whiteboard Update â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private handleWhiteboardUpdate(state: WhiteboardState): void {
    this.currentWhiteboardState = state;

    // Persist whiteboard state to Convex periodically
    if (this.interview) {
      convex
        .mutation(api.interviews.saveWhiteboardState, {
          id: this.interview.id as any,
          whiteboardState: JSON.stringify(state),
        })
        .catch(() => {
          // Non-fatal
        });
    }
  }

  // â”€â”€â”€ Code Result â†’ AI Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async handleCodeResult(
    results: TestResult[],
    stdout: string,
    stderr: string,
    error?: string,
  ): Promise<void> {
    const passed = results.filter((r) => r.passed).length;
    const total = results.length;

    let summary = `\n[Kod Ã‡alÄ±ÅŸtÄ±rma Sonucu]\n`;
    summary += `${passed}/${total} test geÃ§ti.\n`;

    for (let i = 0; i < results.length; i++) {
      const r = results[i]!;
      summary += `Test ${i + 1}: ${r.passed ? "âœ… GeÃ§ti" : `âŒ KaldÄ± â€” Beklenen: ${r.expected}, GerÃ§ek: ${r.actual}`}\n`;
    }

    if (error) summary += `Hata: ${error}\n`;
    if (stderr) summary += `Stderr: ${stderr}\n`;

    // Add to conversation so AI can respond
    this.conversationHistory.push({ role: "user", content: summary });
    this.persistMessage("user", summary);

    // Check if all tests passed for solution comparison (practice mode)
    this.checkSolutionComparison(results);

    // Auto-trigger AI response to comment on the results
    if (this.processing) return;
    this.processing = true;
    this.setState("processing");
    this.abortController = new AbortController();
    const { signal } = this.abortController;

    try {
      const aiResponse = await this.generateAndSpeak(signal);
      if (!aiResponse || signal.aborted) return;

      this.conversationHistory.push({ role: "assistant", content: aiResponse });
      this.persistMessage("assistant", aiResponse);
    } catch (err) {
      if (!signal.aborted) {
        const message = err instanceof Error ? err.message : "Code result response hatasÄ±";
        this.send({ type: "error", message });
      }
    } finally {
      this.processing = false;
      if (!signal.aborted) {
        this.send({ type: "ai_audio_done" });
        this.setState("idle");
      }
      this.abortController = null;
    }
  }

  // â”€â”€â”€ Hint Request â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async handleHintRequest(): Promise<void> {
    if (this.processing) return;
    this.processing = true;
    this.hintCount++;
    const level = Math.min(this.hintCount, 3);

    const hintLevelDescriptions: Record<number, string> = {
      1: "Genel yaklaÅŸÄ±m ipucu ver. Hangi veri yapÄ±sÄ± veya algoritma kullanÄ±labilir sadece onu sÃ¶yle. Detaya girme.",
      2: "Daha detaylÄ± bir yÃ¶nlendirme ver. AdÄ±mlarÄ± kabaca aÃ§Ä±kla ama kodu yazma.",
      3: "Pseudo-code seviyesinde ipucu ver. Ã‡Ã¶zÃ¼mÃ¼n iskeletini gÃ¶ster ama tam kodu verme.",
    };

    const hintPrompt = `[SYSTEM: KullanÄ±cÄ± ipucu istedi (${level}. ipucu, toplam ${this.hintCount} kez istendi). ${hintLevelDescriptions[level]} KÄ±sa ve Ã¶z ol, 2-3 cÃ¼mleyi geÃ§me.]`;

    // Notify client about hint level
    this.send({ type: "hint_given", level, totalHints: this.hintCount });

    // Inject hint request into conversation and trigger AI response
    this.conversationHistory.push({ role: "user", content: hintPrompt });
    this.persistMessage("user", `[Ä°pucu istendi â€” Seviye ${level}]`);

    // Process the hint through the pipeline (LLM â†’ TTS)
    this.setState("processing");
    this.abortController = new AbortController();
    const { signal } = this.abortController;

    try {
      const aiResponse = await this.generateAndSpeak(signal);
      if (!aiResponse || signal.aborted) return;

      this.conversationHistory.push({ role: "assistant", content: aiResponse });
      this.persistMessage("assistant", aiResponse);
    } catch (err) {
      if (!signal.aborted) {
        const message = err instanceof Error ? err.message : "Hint hatasÄ±";
        this.send({ type: "error", message });
      }
    } finally {
      this.processing = false;
      if (!signal.aborted) {
        this.send({ type: "ai_audio_done" });
        this.setState("idle");
      }
      this.abortController = null;
    }
  }

  // â”€â”€â”€ Trigger AI response (for system-injected messages) â”€

  private async triggerAIResponse(): Promise<void> {
    if (this.processing) return;
    this.processing = true;
    this.setState("processing");
    this.abortController = new AbortController();
    const { signal } = this.abortController;

    try {
      const aiResponse = await this.generateAndSpeak(signal);
      if (!aiResponse || signal.aborted) return;

      this.conversationHistory.push({ role: "assistant", content: aiResponse });
      this.persistMessage("assistant", aiResponse);
      this.trackQuestionProgress(aiResponse);
    } catch (err) {
      if (!signal.aborted) {
        const message = err instanceof Error ? err.message : "AI response hatasÄ±";
        this.send({ type: "error", message });
      }
    } finally {
      this.processing = false;
      if (!signal.aborted) {
        this.send({ type: "ai_audio_done" });
        this.setState("idle");
      }
      this.abortController = null;
    }
  }

  // â”€â”€â”€ Question tracking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private trackQuestionProgress(aiResponse: string): void {
    if (!this.interview || this.interview.type !== "phone-screen") return;

    // Heuristic: detect new question in AI response (ends with ?)
    const questionMarks = (aiResponse.match(/\?/g) || []).length;
    const isAskingQuestion = questionMarks > 0 && aiResponse.trim().endsWith("?");

    if (isAskingQuestion && this.currentQuestion < this.totalQuestions) {
      this.currentQuestion++;
      this.send({
        type: "question_update",
        current: Math.min(this.currentQuestion, this.totalQuestions),
        total: this.totalQuestions,
        questionStartTime: Date.now(),
        recommendedSeconds: this.recommendedSecondsPerQuestion,
      });
    }

    // Inject question count awareness into conversation
    if (this.currentQuestion >= this.totalQuestions) {
      const alreadyInjected = this.conversationHistory.some((m) =>
        m.content.includes("[SYSTEM: TÃ¼m sorular soruldu"),
      );
      if (!alreadyInjected) {
        this.conversationHistory.push({
          role: "system",
          content: `[SYSTEM: TÃ¼m sorular soruldu (${this.totalQuestions}/${this.totalQuestions}). Adaya teÅŸekkÃ¼r et ve mÃ¼lakatÄ± sonlandÄ±r.]`,
        });
      }
    }
  }

  // â”€â”€â”€ Solution comparison (practice mode) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private checkSolutionComparison(results: { passed: boolean }[]): void {
    if (!this.interview) return;
    if (this.interview.type !== "practice") return;
    if (!this.currentProblem?.optimalSolution) return;

    const allPassed = results.length > 0 && results.every((r) => r.passed);
    if (allPassed) {
      this.send({
        type: "solution_comparison",
        userSolution: this.currentCode,
        optimalSolution: this.currentProblem.optimalSolution,
        timeComplexity: this.currentProblem.timeComplexity,
        spaceComplexity: this.currentProblem.spaceComplexity,
      });
    }
  }

  // â”€â”€â”€ Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  // Latency tracking fields (reset per pipeline run)
  private _sttMs = 0;
  private _llmFirstTokenMs = 0;
  private _ttsFirstChunkMs = 0;
  private _llmStart = 0;
  private _ttsStart = 0;
  private _llmFirstTokenRecorded = false;
  private _ttsFirstChunkRecorded = false;

  private async processAudio(): Promise<void> {
    if (this.processing) return;
    this.processing = true;
    this.setState("processing");
    this.abortController = new AbortController();
    const { signal } = this.abortController;

    // Reset latency tracking
    this._sttMs = 0;
    this._llmFirstTokenMs = 0;
    this._ttsFirstChunkMs = 0;
    this._llmStart = 0;
    this._ttsStart = 0;
    this._llmFirstTokenRecorded = false;
    this._ttsFirstChunkRecorded = false;

    try {
      // 1) STT (with latency measurement)
      const sttStart = performance.now();
      const transcript = await this.transcribe(signal);
      this._sttMs = Math.round(performance.now() - sttStart);
      if (!transcript || signal.aborted) {
        // STT returned nothing (too short / noise) â€” notify client and go back to idle
        if (!signal.aborted) {
          console.log("[STT] No transcript returned â€” audio too short or unclear");
          this.send({ type: "error", message: "Ses algÄ±lanamadÄ±. LÃ¼tfen tekrar deneyin." });
          this.setState("idle");
        }
        return;
      }

      this.send({ type: "transcript", text: transcript, final: true });

      // Add user message to history
      this.conversationHistory.push({ role: "user", content: transcript });

      // Persist user message to Convex
      await this.persistMessage("user", transcript);

      // 2) LLM + TTS interleaved pipeline (parallel sentence streaming)
      const aiResponse = await this.generateAndSpeak(signal);
      if (!aiResponse || signal.aborted) return;

      this.conversationHistory.push({ role: "assistant", content: aiResponse });
      await this.persistMessage("assistant", aiResponse);
      this.trackQuestionProgress(aiResponse);

      // Send latency report to client
      const totalMs = this._sttMs + this._llmFirstTokenMs + this._ttsFirstChunkMs;
      this.send({
        type: "latency_report",
        sttMs: this._sttMs,
        llmFirstTokenMs: this._llmFirstTokenMs,
        ttsFirstChunkMs: this._ttsFirstChunkMs,
        totalMs,
      });
      console.log(`[Latency] STT: ${this._sttMs}ms | LLM TTFT: ${this._llmFirstTokenMs}ms | TTS TTFB: ${this._ttsFirstChunkMs}ms | Total: ${totalMs}ms`);

      // Reset consecutive errors on successful pipeline
      this.consecutiveErrors = 0;
    } catch (err) {
      if (!signal.aborted) {
        this.consecutiveErrors++;

        // After 3 consecutive errors, signal connection issue
        if (this.consecutiveErrors >= 3) {
          this.send({
            type: "error",
            message: "BaÄŸlantÄ± sorunu. Yeniden baÄŸlanÄ±lÄ±yor...",
            errorType: "connection",
            retry: true,
          });
        } else {
          const message = err instanceof Error ? err.message : "Pipeline hatasÄ±";
          this.send({ type: "error", message });
        }
      }
    } finally {
      this.processing = false;
      if (!signal.aborted) {
        this.send({ type: "ai_audio_done" });
        this.setState("idle");
      }
      this.abortController = null;
    }
  }

  // â”€â”€â”€ Persist â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async persistMessage(role: MessageRole, content: string): Promise<void> {
    if (!this.interview) return;

    try {
      await convex.mutation(api.messages.add, {
        interviewId: this.interview.id as any,
        role,
        content,
      });
    } catch {
      // Non-fatal â€” log but don't break pipeline
      console.error(`Failed to persist ${role} message for interview ${this.interview.id}`);
    }
  }

  // â”€â”€â”€ STT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private async transcribe(signal: AbortSignal): Promise<string | null> {
    // Merge all base64 audio chunks into one buffer
    const combined = Buffer.concat(
      this.audioChunks.map((chunk) => Buffer.from(chunk, "base64")),
    );
    this.audioChunks = [];

    console.log(`[STT] Audio buffer size: ${combined.length} bytes, chunks merged: ${this.audioChunks.length}`);

    if (combined.length < 200) {
      console.log("[STT] Audio too short, skipping transcription");
      return null;
    }

    const formData = new FormData();
    const blob = new Blob([combined], { type: "audio/webm" });
    formData.append("file", blob, "audio.webm");
    formData.append("language", this.config.language);

    console.log(`[STT] Sending ${combined.length} bytes to Freya STT (lang: ${this.config.language})`);

    const response = await fetch(
      `https://fal.run/${ENV.STT_ENDPOINT}/audio/transcriptions`,
      {
        method: "POST",
        headers: { Authorization: `Key ${ENV.FAL_KEY}` },
        body: formData,
        signal,
      },
    );

    if (!response.ok) {
      const errorBody = await response.text().catch(() => "");
      console.error(`[STT] Failed: ${response.status} â€” ${errorBody}`);
      this.send({
        type: "error",
        message: "Ses anlaÅŸÄ±lamadÄ±, tekrar deneyin.",
        errorType: "stt_failed",
        retry: true,
      });
      return null;
    }

    const result = (await response.json()) as { text: string };
    console.log(`[STT] Transcript: "${result.text}"`);
    return result.text?.trim() || null;
  }

  // â”€â”€â”€ Message Preparation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private prepareMessages(): ChatMessage[] {
    const messages = [...this.conversationHistory];

    // Brevity reminder â€” LLMs weigh recent instructions more heavily
    messages.push({
      role: "system",
      content: `[HATIRLATMA] Bu sesli bir konuÅŸmadÄ±r. Normalde 2-3 cÃ¼mle ile kÄ±sa ve Ã¶z yanÄ±t ver. Ancak bir kavramÄ± aÃ§Ä±klaman, problemi tanÄ±tman veya detaylÄ± geri bildirim vermen gerekiyorsa 4-5 cÃ¼mleye kadar Ã§Ä±kabilirsin. Liste yapma, madde madde yazma. DoÄŸal ve akÄ±cÄ± konuÅŸ â€” gerÃ§ek bir sohbet gibi. Her cÃ¼mleni tamamla, yarÄ±da bÄ±rakma.`,
    });

    // Inject code context before the last user message
    if (this.currentCode) {
      const codeContext: ChatMessage = {
        role: "system",
        content: `[AdayÄ±n ÅŸu anki kodu (${this.currentCodeLanguage})]:\n\`\`\`${this.currentCodeLanguage}\n${this.currentCode}\n\`\`\``,
      };
      const lastUserIdx = messages.findLastIndex((m) => m.role === "user");
      if (lastUserIdx >= 0) {
        messages.splice(lastUserIdx, 0, codeContext);
      } else {
        messages.push(codeContext);
      }
    }

    // Inject whiteboard state for system-design interviews
    if (this.currentWhiteboardState) {
      const wbContext: ChatMessage = {
        role: "system",
        content: `[DAHÄ°LÄ° â€” TEKRARLAMA, LÄ°STELEME, ALINTILAMA. Sessizce analiz et.]\n${this.currentWhiteboardState.textRepresentation}`,
      };
      const lastUserIdx = messages.findLastIndex((m) => m.role === "user");
      if (lastUserIdx >= 0) {
        messages.splice(lastUserIdx, 0, wbContext);
      } else {
        messages.push(wbContext);
      }
    }

    return messages;
  }

  // â”€â”€â”€ LLM + TTS Interleaved Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  //
  // Streams LLM tokens, detects sentence boundaries on the fly,
  // and immediately starts TTS for each completed sentence.
  // This overlaps LLM generation with TTS playback for <2s E2E latency.
  // Concurrency: max 1 TTS stream at a time (sequential sentence order).

  private async generateAndSpeak(signal: AbortSignal): Promise<string | null> {
    const messages = this.prepareMessages();

    // â”€â”€ Async sentence queue with notification â”€â”€
    const sentenceQueue: string[] = [];
    let llmDone = false;
    let firstChunkSent = false;
    // Mutable container to avoid TS closure narrowing issues
    const pending: { notify: (() => void) | null } = { notify: null };

    const waitForSentence = (): Promise<void> =>
      new Promise((resolve) => {
        if (sentenceQueue.length > 0 || llmDone) {
          resolve();
          return;
        }
        pending.notify = resolve;
      });

    const pushSentence = (s: string): void => {
      sentenceQueue.push(s);
      pending.notify?.();
      pending.notify = null;
    };

    // â”€â”€ TTS consumer (runs concurrently with LLM producer) â”€â”€
    let hasSwitchedToSpeaking = false;

    // â”€â”€ Sequential TTS with streaming â€” simple & fast â”€â”€
    const ttsConsumer = async (): Promise<void> => {
      while (true) {
        if (signal.aborted) return;
        await waitForSentence();
        if (sentenceQueue.length === 0 && llmDone) break;

        const sentence = sentenceQueue.shift();
        if (!sentence) continue;

        if (!hasSwitchedToSpeaking) {
          hasSwitchedToSpeaking = true;
          this.setState("speaking");
          this._ttsStart = performance.now();
          this._ttsFirstChunkRecorded = false;
        }

        await this.synthesizeSentence(sentence, signal);
      }
    };

    // Start TTS consumer in background
    const ttsPromise = ttsConsumer();

    // â”€â”€ LLM producer (stream tokens â†’ detect sentences â†’ push to queue) â”€â”€
    let fullText = "";
    let sentenceBuffer = "";

    // Record LLM start time for TTFT measurement
    this._llmStart = performance.now();
    this._llmFirstTokenRecorded = false;

    try {
      const response = await fetch(
        "https://openrouter.ai/api/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${ENV.OPENROUTER_API_KEY}`,
            "Content-Type": "application/json",
            "HTTP-Referer": ENV.SITE_URL,
            "X-Title": "Wingman AI Interview",
          },
          body: JSON.stringify({
            model: ENV.OPENROUTER_MODEL,
            messages,
            stream: true,
            max_tokens: 500,
            temperature: 0.7,
          }),
          signal,
        },
      );

      if (!response.ok) {
        if (response.status === 429) {
          this.send({
            type: "error",
            message: "AI meÅŸgul, tekrar deneniyor...",
            errorType: "llm_timeout",
            retry: true,
          });
        } else {
          this.send({
            type: "error",
            message: "AI yanÄ±t veremedi.",
            errorType: "llm_failed",
            retry: true,
          });
        }
        return null;
      }

      const reader = response.body?.getReader();
      if (!reader) throw new Error("No response stream");

      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader.read();
        if (done || signal.aborted) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split("\n");

        for (const line of lines) {
          if (!line.startsWith("data: ")) continue;
          const data = line.slice(6).trim();
          if (data === "[DONE]") continue;

          try {
            const parsed = JSON.parse(data);
            const token = parsed.choices?.[0]?.delta?.content;
            if (!token) continue;

            // Record LLM first token latency (TTFT)
            if (!this._llmFirstTokenRecorded) {
              this._llmFirstTokenMs = Math.round(performance.now() - this._llmStart);
              this._llmFirstTokenRecorded = true;
            }

            fullText += token;
            sentenceBuffer += token;

            // Stream text to client immediately â€” token by token
            this.send({ type: "ai_text", text: token, done: false });

            // â”€â”€ Chunk splitting â”€â”€
            // First chunk: fire ASAP at ~3 words for lowest TTFB
            // After that: split at sentence/clause boundaries for natural speech
            let splitIdx = -1;
            let skipChars = 0;

            if (!firstChunkSent) {
              // FIRST CHUNK: exactly 3 words, ignore all punctuation
              const words = sentenceBuffer.split(/\s+/);
              if (words.length >= 4) {
                // Find end of 3rd word in the buffer
                let pos = 0;
                for (let w = 0; w < 3; w++) {
                  pos = sentenceBuffer.indexOf(words[w]!, pos) + words[w]!.length;
                }
                splitIdx = pos;
                // skip whitespace after split
                if (sentenceBuffer[splitIdx] === " ") skipChars = 1;
              }
            } else {
              // REST: sentence enders (.!?) â€” always split
              const sentenceEnd = sentenceBuffer.search(/[.!?]\s/);
              if (sentenceEnd !== -1) {
                splitIdx = sentenceEnd + 1;
                skipChars = 1;
              }

              // Comma/semicolon â€” split if buffer is long enough
              if (splitIdx === -1 && sentenceBuffer.length >= 25) {
                const clauseEnd = sentenceBuffer.search(/[,;:]\s/);
                if (clauseEnd !== -1 && clauseEnd >= 12) {
                  splitIdx = clauseEnd + 1;
                  skipChars = 1;
                }
              }
            }

            if (splitIdx !== -1) {
              const chunk = sentenceBuffer.slice(0, splitIdx).trim();
              sentenceBuffer = sentenceBuffer.slice(splitIdx + skipChars);
              if (chunk.length >= 3) {
                if (!firstChunkSent) {
                  firstChunkSent = true;
                  console.log(`[TTS] First chunk fired (${chunk.length} chars): "${chunk}"`);
                }
                const optimized =
                  this.interview?.language === "tr"
                    ? optimizeForTTS(chunk)
                    : chunk;
                pushSentence(optimized);
              }
            }
          } catch {
            // skip unparseable SSE chunks
          }
        }
      }

      // Flush remaining text as final sentence
      const remaining = sentenceBuffer.trim();
      if (remaining) {
        const optimized =
          this.interview?.language === "tr"
            ? optimizeForTTS(remaining)
            : remaining;
        pushSentence(optimized);
      }

    } catch (err) {
      // LLM network/fetch error â€” send granular error if not aborted
      if (!signal.aborted) {
        const isAbortError = err instanceof Error && err.name === "AbortError";
        if (!isAbortError) {
          this.send({
            type: "error",
            message: "AI yanÄ±t veremedi, tekrar deneniyor...",
            errorType: "llm_timeout",
            retry: true,
          });
        }
      }
    } finally {
      // Signal TTS consumer that LLM is done
      llmDone = true;
      pending.notify?.();
      // Text is fully streamed â€” tell client
      this.send({ type: "ai_text", text: "", done: true });
    }

    // Wait for all TTS sentences to finish playing
    await ttsPromise;

    return fullText || null;
  }

  // â”€â”€â”€ Single Sentence TTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Raw fetch SSE to /stream â€” skips fal SDK overhead (~200ms saving)

  private async synthesizeSentence(
    text: string,
    signal: AbortSignal,
  ): Promise<void> {
    if (signal.aborted || !text) return;

    const optimizedText = this.interview?.language === "tr" ? optimizeForTTS(text) : text;

    try {
      const response = await fetch(
        `https://fal.run/${ENV.TTS_ENDPOINT}/stream`,
        {
          method: "POST",
          headers: {
            Authorization: `Key ${ENV.FAL_KEY}`,
            "Content-Type": "application/json",
            Accept: "text/event-stream",
          },
          body: JSON.stringify({
            input: optimizedText,
            speed: this.config.speed,
          }),
          signal,
        },
      );

      if (!response.ok) {
        // Fallback to /audio/speech
        return this.synthesizeSentenceFallback(optimizedText, signal);
      }

      const reader = response.body?.getReader();
      if (!reader) return this.synthesizeSentenceFallback(optimizedText, signal);

      const decoder = new TextDecoder();
      let buffer = "";

      while (true) {
        if (signal.aborted) return;
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });

        // Parse SSE events from buffer
        const parts = buffer.split("\n\n");
        buffer = parts.pop() ?? ""; // keep incomplete last part

        for (const part of parts) {
          const dataLine = part.split("\n").find((l) => l.startsWith("data: "));
          if (!dataLine) continue;

          try {
            const event = JSON.parse(dataLine.slice(6));
            if (event.audio) {
              if (!this._ttsFirstChunkRecorded && this._ttsStart > 0) {
                this._ttsFirstChunkMs = Math.round(performance.now() - this._ttsStart);
                this._ttsFirstChunkRecorded = true;
              }
              this.send({ type: "ai_audio", data: event.audio });
            }
          } catch {
            // skip malformed events
          }
        }
      }
    } catch {
      if (signal.aborted) return;
      return this.synthesizeSentenceFallback(optimizedText, signal);
    }
  }

  // Fallback: /audio/speech (non-streaming, full audio)
  private async synthesizeSentenceFallback(
    text: string,
    signal: AbortSignal,
  ): Promise<void> {
    if (signal.aborted) return;
    try {
      const response = await fetch(
        `https://fal.run/${ENV.TTS_ENDPOINT}/audio/speech`,
        {
          method: "POST",
          headers: {
            Authorization: `Key ${ENV.FAL_KEY}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            input: text,
            response_format: "pcm",
            speed: this.config.speed,
          }),
          signal,
        },
      );
      if (!response.ok) return;
      const arrayBuffer = await response.arrayBuffer();
      if (!this._ttsFirstChunkRecorded && this._ttsStart > 0) {
        this._ttsFirstChunkMs = Math.round(performance.now() - this._ttsStart);
        this._ttsFirstChunkRecorded = true;
      }
      this.send({ type: "ai_audio", data: Buffer.from(arrayBuffer).toString("base64") });
    } catch {
      if (signal.aborted) return;
      this.send({
        type: "error",
        message: "Ses oluÅŸturulamadÄ± â€” metin olarak gÃ¶steriliyor.",
        errorType: "tts_failed",
        retry: false,
        fallbackText: text,
      });
    }
  }



  // â”€â”€â”€ Interrupt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private handleInterrupt(): void {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
    this.processing = false;
    this.send({ type: "ai_audio_done" });
    this.setState("idle");
    this.audioChunks = [];
  }

  // â”€â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  private setState(state: VoicePipelineState): void {
    this.state = state;
    this.send({ type: "state_change", state });
  }

  cleanup(): void {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
    if (this.timeWarningTimer) {
      clearTimeout(this.timeWarningTimer);
      this.timeWarningTimer = null;
    }
    if (this.timeUpTimer) {
      clearTimeout(this.timeUpTimer);
      this.timeUpTimer = null;
    }

  }

  /**
   * Generate and stream intro audio for problems.
   * Uses abortController so interrupts can cancel it.
   */
  private async generateIntroAudio(text: string): Promise<void> {
    this.processing = true;
    this.abortController = new AbortController();
    const { signal } = this.abortController;

    try {
      this.setState("speaking");
      await this.synthesizeSentence(text, signal);
    } catch (error) {
      if (signal.aborted) return;
      console.error("Error generating intro audio:", error);
      this.conversationHistory.push({
        role: "user",
        content: "[SYSTEM: KullanÄ±cÄ± hazÄ±r, problemi aÃ§Ä±klamaya baÅŸla]",
      });
      this.triggerAIResponse();
      return;
    } finally {
      this.processing = false;
      if (!signal.aborted) {
        this.send({ type: "ai_audio_done" });
        this.setState("idle");
      }
      this.abortController = null;
    }
  }
}
