# Faz 1 â€” Sesli AI AjanÄ± (Voice Pipeline)

> **Ã–ncelik:** ðŸ”´ P0  
> **BaÄŸÄ±mlÄ±lÄ±k:** Faz 0 (altyapÄ± doÄŸrulanmÄ±ÅŸ olmalÄ±)  
> **Tahmini sÃ¼re:** 3-5 gÃ¼n

## AmaÃ§

KullanÄ±cÄ±nÄ±n mikrofonuyla konuÅŸup AI'dan sesli cevap alabildiÄŸi temel dÃ¶ngÃ¼yÃ¼ kur. Bu, platformun kalbi. TÃ¼m mÃ¼lakat modÃ¼lleri (Live Coding, System Design, Phone Screen) bu pipeline Ã¼zerine inÅŸa edilecek.

**Hedef akÄ±ÅŸ:**
```
ðŸŽ™ï¸ Mikrofon â†’ ðŸ“ STT (Freya) â†’ ðŸ§  LLM (OpenRouter) â†’ ðŸ”Š TTS (Freya) â†’ ðŸ”ˆ HoparlÃ¶r
```

---

## Mimari Kararlar

### WebSocket vs REST

Voice pipeline iÃ§in **WebSocket** tercih edilmeli:
- Ses verisi sÃ¼rekli akar (half-duplex ya da full-duplex)
- SÃ¶z kesme (interrupt) iÃ§in anÄ±nda sinyal gerekli
- REST'te her istek yeni TCP baÄŸlantÄ±sÄ± = gereksiz latency

**Hono WebSocket (Bun runtime):**
```typescript
// Hono'da Bun iÃ§in WebSocket:
import { upgradeWebSocket, websocket } from "hono/bun"

app.get("/ws/voice", upgradeWebSocket((c) => ({
  onOpen(event, ws) { /* ... */ },
  onMessage(event, ws) { /* ses verisi geldi */ },
  onClose() { /* temizle */ },
})))

export default { fetch: app.fetch, websocket }
```

### Ses FormatÄ±

| YÃ¶n | Format | Detay |
|-----|--------|-------|
| Browser â†’ API | WebM/Opus veya PCM16 | MediaRecorder varsayÄ±lan: WebM/Opus |
| API â†’ Freya STT | WAV veya raw audio | STT multipart form-data bekler |
| Freya TTS â†’ API | PCM16 (streaming) veya WAV | Streaming: base64 PCM16 chunk'lar |
| API â†’ Browser | PCM16 veya WAV | AudioContext ile PCM16 decode |

---

## GÃ¶revler

### 1.1 â€” Ses Yakalama (Browser TarafÄ±)

Web tarafÄ±nda mikrofon eriÅŸimi ve ses verisini API'ye gÃ¶nderme.

- [ ] `getUserMedia({ audio: true })` ile mikrofon eriÅŸimi
- [ ] `MediaRecorder` veya `AudioWorklet` ile ses kaydÄ±
  - MediaRecorder: Daha basit, WebM/Opus chunk'lar Ã¼retir
  - AudioWorklet: Daha dÃ¼ÅŸÃ¼k latency, raw PCM eriÅŸimi (ileri seviye)
- [ ] VAD (Voice Activity Detection) implementasyonu
  - Basit yaklaÅŸÄ±m: Volume threshold (RMS energy) ile sessizlik algÄ±lama
  - Ä°leri yaklaÅŸÄ±m: `@ricky0123/vad-web` veya benzeri WebAssembly VAD
  - KullanÄ±cÄ± konuÅŸmayÄ± bÄ±rakÄ±nca ~500ms sonra chunk'Ä± gÃ¶nder
- [ ] Ses chunk'larÄ±nÄ± WebSocket Ã¼zerinden API'ye gÃ¶nderme
- [ ] Mikrofon aÃ§ma/kapama toggle UI kontrolÃ¼
- [ ] Ses seviyesi gÃ¶stergesi (volume meter) â€” `AnalyserNode` ile

**Browser API'larÄ±:**
- `navigator.mediaDevices.getUserMedia()`
- `MediaRecorder` API
- `AudioContext` + `AnalyserNode`
- `WebSocket` API

---

### 1.2 â€” WebSocket Voice Endpoint (API TarafÄ±)

API'de WebSocket baÄŸlantÄ±sÄ± kabul eden voice endpoint.

- [ ] `apps/api/src/index.ts`'ye Hono WebSocket desteÄŸi ekle
  - `import { upgradeWebSocket, websocket } from "hono/bun"` 
  - `export default { fetch: app.fetch, websocket }` (Bun iÃ§in zorunlu)
- [ ] `/ws/voice` WebSocket endpoint'i oluÅŸtur
- [ ] WebSocket mesaj protokolÃ¼ tanÄ±mla:

```typescript
// Client â†’ Server mesajlarÄ±
type ClientMessage =
  | { type: "audio_chunk"; data: string }       // base64 audio
  | { type: "start_listening" }
  | { type: "stop_listening" }
  | { type: "interrupt" }                        // AI'Ä± kes
  | { type: "config"; settings: SessionConfig }

// Server â†’ Client mesajlarÄ±
type ServerMessage =
  | { type: "transcript"; text: string; final: boolean }
  | { type: "ai_text"; text: string; done: boolean }
  | { type: "ai_audio"; data: string }           // base64 PCM16
  | { type: "ai_audio_done" }
  | { type: "state_change"; state: VoicePipelineState }
  | { type: "error"; message: string }
```

- [ ] Her baÄŸlantÄ± iÃ§in session state yÃ¶netimi
- [ ] BaÄŸlantÄ± kopma durumunda cleanup

**Dosyalar:**
- `apps/api/src/index.ts` â€” WebSocket export ekle
- `apps/api/src/ws/voice.ts` â€” Yeni dosya, voice WebSocket handler
- `packages/types/src/index.ts` â€” WebSocket mesaj tipleri

---

### 1.3 â€” STT Pipeline (Ses â†’ Metin)

API tarafÄ±nda gelen ses verisini Freya STT'ye gÃ¶ndererek metin alma.

- [ ] Gelen audio chunk'larÄ± birleÅŸtirme (buffer)
- [ ] VAD sinyali ile tamamlanan konuÅŸmayÄ± STT'ye gÃ¶nderme
- [ ] Freya STT'ye multipart form-data ile istek:

```typescript
// docs/freya-pipeline.ts referansÄ±:
const formData = new FormData();
const blob = new Blob([audioBuffer], { type: "audio/wav" });
formData.append("file", blob, "audio.wav");
formData.append("language", "tr");

const response = await fetch(
  `https://fal.run/${STT_ENDPOINT}/audio/transcriptions`,
  {
    method: "POST",
    headers: { Authorization: `Key ${FAL_KEY}` },
    body: formData,
  }
);
const result = await response.json(); // { text: "..." }
```

- [ ] WebM/Opus â†’ WAV dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (gerekirse, ffmpeg-wasm veya Bun native)
- [ ] Transkript sonucunu WebSocket Ã¼zerinden client'a gÃ¶nderme
- [ ] Dil parametresi: VarsayÄ±lan `"tr"`, config ile deÄŸiÅŸtirilebilir
- [ ] Hata yÃ¶netimi: STT fail ederse client'a error mesajÄ±

**Referans:** `docs/freya-pipeline.ts` â†’ `transcribeAudio()` fonksiyonu

---

### 1.4 â€” LLM Ä°ÅŸleme (Metin â†’ AI Cevap)

KullanÄ±cÄ±nÄ±n transkriptini LLM'e gÃ¶nderip AI cevabÄ± alma.

- [ ] OpenRouter chat completion entegrasyonu (OpenAI-compat API)
- [ ] System prompt ile AI mÃ¼lakatÃ§Ä± persona tanÄ±mlama
- [ ] Conversation history yÃ¶netimi â€” mesaj dizisi (messages array)
- [ ] **Streaming response**: Token token cevap alma

```typescript
// OpenRouter streaming Ã¶rneÄŸi:
const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${OPENROUTER_API_KEY}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    model: "google/gemini-2.5-flash",
    messages: conversationHistory,
    stream: true,
  }),
});

// SSE stream okuma
const reader = response.body.getReader();
const decoder = new TextDecoder();
// ... chunk chunk oku, parse et
```

- [ ] Her token geldiÄŸinde WebSocket'e `ai_text` mesajÄ± gÃ¶nder
- [ ] CÃ¼mle bazlÄ± chunking: Noktalama iÅŸaretlerinde TTS'e gÃ¶ndermeye baÅŸla
- [ ] AbortController ile devam eden isteÄŸi iptal edebilme (interrupt iÃ§in)

---

### 1.5 â€” TTS Pipeline (AI Cevap â†’ Ses)

LLM cevabÄ±nÄ± Freya TTS'e gÃ¶nderip ses Ã¼retme.

- [ ] **Streaming TTS** tercih et (dÃ¼ÅŸÃ¼k latency):

```typescript
// docs/freya-tts-streaming.ts referansÄ±:
const stream = await fal.stream(TTS_ENDPOINT, {
  input: { input: text, speed: 1.0 },
  path: "/stream",
});

for await (const event of stream) {
  if (event.audio) {
    const pcmBytes = Buffer.from(event.audio, "base64");
    // WebSocket Ã¼zerinden client'a gÃ¶nder
    ws.send(JSON.stringify({ type: "ai_audio", data: event.audio }));
  }
  if (event.done) {
    ws.send(JSON.stringify({ type: "ai_audio_done" }));
  }
}
```

- [ ] CÃ¼mle bazlÄ± TTS: LLM'den cÃ¼mle tamamlandÄ±ÄŸÄ±nda hemen TTS'e gÃ¶nder
- [ ] PCM16 chunk'larÄ± WebSocket Ã¼zerinden client'a ilet
- [ ] Fallback: Streaming baÅŸarÄ±sÄ±z olursa `/audio/speech` ile tam WAV Ã¼ret
- [ ] TTS parametreleri: `speed` (1.0 varsayÄ±lan), `response_format`

**Referans:** `docs/freya-tts-streaming.ts` â†’ `streamSpeech()` fonksiyonu

---

### 1.6 â€” Ses Oynatma (Browser TarafÄ±)

API'den gelen PCM16 chunk'larÄ± browser'da oynatma.

- [ ] `AudioContext` oluÅŸtur (user gesture sonrasÄ±, autoplay policy)
- [ ] PCM16 base64 chunk'larÄ± decode et â†’ `Float32Array`
- [ ] `AudioBuffer` oluÅŸturup `AudioBufferSourceNode` ile oynat
- [ ] Chunk queue sistemi: Chunk'lar sÄ±rayla ve kesintisiz oynatÄ±lmalÄ±
- [ ] Playback durumunu takip et: OynatÄ±lÄ±yor / Bitti
- [ ] Ses seviyesi kontrolÃ¼ (gain node)

```typescript
// PCM16 â†’ Float32Array dÃ¶nÃ¼ÅŸÃ¼mÃ¼:
function decodePCM16(base64: string): Float32Array {
  const bytes = Uint8Array.from(atob(base64), c => c.charCodeAt(0));
  const pcm16 = new Int16Array(bytes.buffer);
  const float32 = new Float32Array(pcm16.length);
  for (let i = 0; i < pcm16.length; i++) {
    float32[i] = pcm16[i] / 32768; // Normalize to [-1, 1]
  }
  return float32;
}
```

---

### 1.7 â€” SÃ¶z Kesme (Interruptibility)

KullanÄ±cÄ± konuÅŸmaya baÅŸladÄ±ÄŸÄ±nda AI'Ä± anÄ±nda durdurma.

- [ ] VAD algÄ±ladÄ±ÄŸÄ±nda client'tan `{ type: "interrupt" }` mesajÄ± gÃ¶nder
- [ ] API tarafÄ±nda interrupt sinyali geldiÄŸinde:
  1. Aktif LLM stream'ini iptal et (`AbortController.abort()`)
  2. Aktif TTS stream'ini iptal et
  3. Client'a `{ type: "ai_audio_done" }` gÃ¶nder (oynatmayÄ± durdur)
  4. State'i `LISTENING`'e geÃ§ir
- [ ] Client tarafÄ±nda interrupt olduÄŸunda:
  1. Audio queue'yu temizle
  2. Mevcut playback'i durdur
  3. Mikrofonu aktif et (zaten aktifse devam)

---

### 1.8 â€” State Machine

Voice pipeline'Ä±n tÃ¼m state geÃ§iÅŸlerini yÃ¶net.

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   IDLE   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚
     â”‚                â”‚ kullanÄ±cÄ± konuÅŸmaya baÅŸladÄ±
     â”‚          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”             â”‚
     â”‚     â”Œâ”€â”€â”€â–ºâ”‚LISTENING â”‚â”€â”€â”€ interrupt â”˜
     â”‚     â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚     â”‚          â”‚ VAD: konuÅŸma bitti
     â”‚     â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚     â”‚    â”‚ PROCESSING â”‚ (STT + LLM)
     â”‚     â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚     â”‚          â”‚ LLM cevap vermeye baÅŸladÄ±
     â”‚     â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚     â””â”€â”€â”€â”€â”‚ SPEAKING  â”‚ â† interrupt â†’ LISTENING
     â”‚          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                â”‚ TTS bitti
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- [ ] State enum'u `packages/types`'ta tanÄ±mla (Faz 0.6'da yapÄ±ldÄ±)
- [ ] Her state deÄŸiÅŸikliÄŸinde client'a `state_change` mesajÄ± gÃ¶nder
- [ ] State'e gÃ¶re UI gÃ¼ncellemesi (Faz 9'da implemente edilecek)
- [ ] GeÃ§ersiz state geÃ§iÅŸlerini engelle (guard'lar)

---

### 1.9 â€” UÃ§tan Uca Test

TÃ¼m pipeline'Ä±n birlikte Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrula.

- [ ] Manuel test: Mikrofon â†’ STT â†’ LLM â†’ TTS â†’ HoparlÃ¶r tam dÃ¶ngÃ¼
- [ ] Latency Ã¶lÃ§Ã¼mÃ¼ (her adÄ±m):
  - STT sÃ¼resi: Ses gÃ¶nderiminden transkript almaya
  - LLM first token: Transkript gÃ¶nderiminden ilk token'a
  - TTS first chunk: LLM cÃ¼mle tamamÄ±ndan ilk PCM chunk'a
  - Toplam round-trip: KullanÄ±cÄ± susmasÄ±ndan ilk AI sesine
- [ ] Hata senaryolarÄ± test:
  - Mikrofon eriÅŸimi reddedilirse
  - WebSocket baÄŸlantÄ±sÄ± koparsa
  - STT/LLM/TTS timeout olursa
  - Birden fazla hÄ±zlÄ± interrupt

---

## Tamamlanma Kriterleri

1. KullanÄ±cÄ± mikrofona konuÅŸuyor, AI sesli cevap veriyor
2. AI konuÅŸurken araya girilebiliyor (interrupt Ã§alÄ±ÅŸÄ±yor)
3. Toplam round-trip latency < 3 saniye (hedef < 1.5s)
4. KonuÅŸma TÃ¼rkÃ§e yapÄ±labiliyor
5. WebSocket baÄŸlantÄ± kopmasÄ±nda graceful recovery
6. State machine tÃ¼m geÃ§iÅŸlerde doÄŸru Ã§alÄ±ÅŸÄ±yor
